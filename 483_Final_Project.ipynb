{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedanth-i/483-final-project/blob/main/483_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tex07RZO_rFI"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# geometric_libs = '/content/notebooks'\n",
        "# os.symlink(\"/content/drive/MyDrive/Colab Notebooks\", geometric_libs)\n",
        "# sys.path.insert(0,geometric_libs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lvXY5Ic_pW9",
        "outputId": "a054ff14-d888-41b7-c747-b2175efb9744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.1.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPiT62Ks_9PH",
        "outputId": "843105c3-df7d-45c6-97bf-12d574ec3b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --target=$geometric_libs torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "#can skip this step next time since already installed on drive\n",
        "#!pip install -r \"/content/drive/MyDrive/Colab Notebooks/requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l21rE2L1_6Eb",
        "outputId": "da45efbb-767e-49ab-8f0a-62dc3ca14eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --target=$geometric_libs ogb\n",
        "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "# !pip install ogb  # for datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NYvvXigRCCx2"
      },
      "outputs": [],
      "source": [
        "import torch_scatter, torch_sparse, torch_cluster, torch_spline_conv, torch_geometric, ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gtxYGk8KAKvm"
      },
      "outputs": [],
      "source": [
        "# import torch_geometric.data into environment\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric import nn\n",
        "import torch_geometric.transforms as T\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-GiBBMgcAK1M"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Amazon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UGtlXzAp9LBY",
        "outputId": "5cd68cfa-f5e2-4adf-f5dd-fdd9f4db750d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset_computers = Amazon('/tmp/amazoncomputers', 'Computers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fao_enSV9-Gr",
        "outputId": "665276c1-83c0-4375-fd97-d2ec8ba408a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_photo.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset_photos = Amazon('/tmp/amazonphotos', 'Photo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7dq3KctJ-N1c",
        "outputId": "36eba18f-d1da-40fd-c5d1-24ed7c90e06f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_computers.num_classes, dataset_photos.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_GIzPoJINXKm"
      },
      "outputs": [],
      "source": [
        "class MLP1(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(1, -1)\n",
        "        out = 0\n",
        "\n",
        "        out = self.layer_1(x) #linear 1\n",
        "        out = self.act(out) #relu\n",
        "        out = self.layer_2(out) #linear 2\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3jNhKxS0tlRv"
      },
      "outputs": [],
      "source": [
        "#CHANGE HERE these values to get results\n",
        "\n",
        "hidden_channels = 200 #can change number of hidden channels for variability\n",
        "l_rate = 0.01 #learning rate\n",
        "split = 11000 #train/test split.\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d0hojVFN1iMm"
      },
      "outputs": [],
      "source": [
        "#Computers dataset\n",
        "\n",
        "num_features_computers = dataset_computers.num_features\n",
        "num_classes_computers = dataset_computers.num_classes # please write down the number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZS00jxIbUYmM"
      },
      "outputs": [],
      "source": [
        "#Photos dataset\n",
        "\n",
        "\n",
        "num_features_photos = dataset_photos.num_features\n",
        "num_classes_photos = dataset_photos.num_classes # please write down the number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IBPLWfhoTyDD"
      },
      "outputs": [],
      "source": [
        "#define model here\n",
        "\n",
        "#MLP Model\n",
        "\n",
        "model_1_computers = MLP1(num_features_computers, hidden_channels, num_classes_computers)\n",
        "model_1_photos = MLP1(num_features_photos, hidden_channels, num_classes_photos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nPOFix9C2BRb"
      },
      "outputs": [],
      "source": [
        "optimizer_1_computers = optim.Adam(model_1_computers.parameters(), lr=l_rate)\n",
        "optimizer_1_photos = optim.Adam(model_1_photos.parameters(), lr=l_rate) #play around with the learning rate for differentiating\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_ra_o24IMVsx"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i in range(0, split): #train/test split is 0.8/0.2. For computers, 0.8*13,752 = 11000. For photos 0.8*7650 = 6048\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      y_pred = model(data.x[i])\n",
        "\n",
        "\n",
        "      y_actual = torch.zeros(1,10)\n",
        "      y_actual[0][data.y[i]] = 1\n",
        "\n",
        "      torch.squeeze(y_pred, dim=0)\n",
        "      #print(y_pred.shape, data.y.shape, data.y, y_pred)\n",
        "\n",
        "      l = loss_fn(y_pred, y_actual)  # calculate the loss\n",
        "\n",
        "      l.backward()  # calculate the gradients of each parameter\n",
        "\n",
        "      optimizer.step()  # update the parameters by taking an optimizer step\n",
        "\n",
        "      loss += l.item()\n",
        "\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pblJ0YrdYnZy",
        "outputId": "a24431b5-4bbd-4770-d42c-d99f929e1f69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(Data(x=[13752, 767], edge_index=[2, 491722], y=[13752]), 767, 10)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_computers.data, dataset_computers.num_features, dataset_computers.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hf4DIeLTX-yz",
        "outputId": "843e96f7-852d-4d84-b6b9-98fc54e559e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Data(x=[7650, 745], edge_index=[2, 238162], y=[7650]), 745, 8)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_photos.data, dataset_photos.num_features, dataset_photos.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9_kuoSp-wLYa"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(pred, label):\n",
        "\n",
        "  acc = 0.0\n",
        "\n",
        "  new = torch.softmax(pred, dim=1).argmax(dim=1)\n",
        "  # print(new, new.shape)\n",
        "  # print(label.shape)\n",
        "  final = torch.eq(new, label).sum().item()\n",
        "  acc = final/len(pred)\n",
        "\n",
        "\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BtIBO0D4vet5"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    for i in range(split, len(data.y)): #0.2 split for testing. Remainder of examples used. For computers, ~2750 examples. For photos ~1512\n",
        "\n",
        "      y_pred = model(data.x[i])\n",
        "\n",
        "      y_actual = torch.zeros(1,10)\n",
        "      y_actual[0][data.y[i]] = 1\n",
        "\n",
        "      #print(y_pred.shape, data.y.shape, data.y, y_pred)\n",
        "\n",
        "      l = loss_fn(y_pred, y_actual)\n",
        "      loss += l.item()\n",
        "      epoch_acc += calculate_accuracy(y_pred, y_actual)\n",
        "\n",
        "\n",
        "    return epoch_acc / len(data.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "XZzqbOakY4ZL",
        "outputId": "90a69592-641e-492d-bb9f-9d02c7e10d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16454.424340512167\n",
            "14225.964838509126\n",
            "13282.32605326739\n",
            "13633.966436936806\n",
            "13150.41147286529\n",
            "12973.924073203078\n",
            "13570.500383351022\n",
            "12340.400008688783\n",
            "12697.82826375557\n",
            "13286.450244209776\n",
            "12227.133865755079\n",
            "12469.326646800439\n",
            "10844.910644144156\n",
            "11521.522878531892\n",
            "12186.617009594973\n",
            "12285.837621108514\n",
            "12262.486194462566\n",
            "11641.228814880576\n",
            "11096.556137154694\n",
            "10793.456572018673\n",
            "11712.999302335691\n",
            "11661.830749156434\n",
            "11086.151141838516\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-aeb6cb1f9d57>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1_computers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_computers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_1_computers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-6c8c9046e0c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# calculate the gradients of each parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update the parameters by taking an optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_val_acc = final_test_acc = 0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train(model_1_computers, dataset_computers.data, optimizer_1_computers, loss_fn)\n",
        "    print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wwxWmzc4Q2wO"
      },
      "outputs": [],
      "source": [
        "#Save model's parameters like such. Can change parameters depending on what model you want to save\n",
        "torch.save(model_1_photos.state_dict(), 'model_photos_200_0.001.pt')  # saving model's parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zK1uo-kqRFIy"
      },
      "outputs": [],
      "source": [
        "test_acc = evaluate(model_1_computers, dataset_computers.data, loss_fn)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "swSuk_b4kjJa"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN1(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.act = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, node_feature, edge_index):\n",
        "\n",
        "        output = self.conv1(node_feature, edge_index)\n",
        "        output = self.act(output)\n",
        "\n",
        "        #Can add/remove GCN layers\n",
        "\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "\n",
        "\n",
        "        output = self.conv2(output, edge_index)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bGRjq3xxuugR"
      },
      "outputs": [],
      "source": [
        "#CHANGE HERE these values to get results\n",
        "\n",
        "hidden_channels = 200 #can change number of hidden channels for variability\n",
        "l_rate = 0.01 #learning rate\n",
        "split = 11000 #train/test split\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sQYvPmdc-CAO"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Computers and Photos\n",
        "\n",
        "num_features_computers = dataset_computers.num_features\n",
        "num_classes_computers = dataset_computers.num_classes # please write down the number of classes\n",
        "\n",
        "num_features_photos = dataset_photos.num_features\n",
        "num_classes_photos = dataset_photos.num_classes # please write down the number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KXWvFBWaj6QG"
      },
      "outputs": [],
      "source": [
        "#GCN Models\n",
        "gcn_computers = GCN1(num_features_computers, hidden_channels, num_classes_computers)\n",
        "gcn_photos = GCN1(num_features_photos, hidden_channels, num_classes_photos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FpTMuD_ykLab"
      },
      "outputs": [],
      "source": [
        "#GCN Optimizers\n",
        "gcn_opt_computers = optim.Adam(gcn_computers.parameters(), lr=l_rate)\n",
        "gcn_opt_photos = optim.Adam(gcn_photos.parameters(), lr=l_rate) #play around with the learning rate for differentiating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "H1FXTgXSqea9"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9NVC4ytUkvxm"
      },
      "outputs": [],
      "source": [
        "def trainGCN(model, data, optimizer, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(data.x, data.edge_index)\n",
        "\n",
        "    l = loss_fn(y_pred[:split], data.y.view(-1)[:split])  # calculate the loss\n",
        "\n",
        "    l.backward()  # calculate the gradients of each parameter\n",
        "\n",
        "    optimizer.step()  # update the parameters by taking an optimizer step\n",
        "\n",
        "    loss += l.item()\n",
        "\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "s_zWbF76m-U3"
      },
      "outputs": [],
      "source": [
        "def testGCN(model, data):\n",
        "\n",
        "\n",
        "  acc = 0\n",
        "  model.eval()\n",
        "  pred = model(data.x, data.edge_index)\n",
        "  print(pred.shape)\n",
        "\n",
        "  predicted_classes = torch.argmax(pred[split:], dim=1)\n",
        "  acc = torch.mean((predicted_classes == data.y[split:]).float()).item()\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8pHT11cAnYs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd8397b-6854-4a4a-9012-525494fd837b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2540762424468994\n",
            "9.513840675354004\n",
            "9.907833099365234\n",
            "6.928719520568848\n",
            "4.022804260253906\n",
            "2.996025323867798\n",
            "2.318814516067505\n",
            "2.543565034866333\n",
            "2.425250768661499\n",
            "2.1283323764801025\n",
            "1.9522950649261475\n",
            "1.9743455648422241\n",
            "1.934085726737976\n",
            "1.771753191947937\n",
            "1.6756209135055542\n",
            "1.6685841083526611\n",
            "1.7079312801361084\n",
            "1.7113721370697021\n",
            "1.632947564125061\n",
            "1.539300560951233\n",
            "1.490108847618103\n",
            "1.4760775566101074\n",
            "1.4591832160949707\n",
            "1.4231340885162354\n",
            "1.3625049591064453\n",
            "1.3452816009521484\n",
            "1.2860833406448364\n",
            "1.2724738121032715\n",
            "1.2334543466567993\n",
            "1.213301181793213\n",
            "1.2233988046646118\n",
            "1.1295855045318604\n",
            "1.0921144485473633\n",
            "1.074951171875\n",
            "1.0534697771072388\n",
            "1.033928394317627\n",
            "1.0026543140411377\n",
            "0.967704713344574\n",
            "0.9404873251914978\n",
            "0.920881986618042\n",
            "0.9030722379684448\n",
            "0.8816046714782715\n",
            "0.878686249256134\n",
            "0.8373917937278748\n",
            "0.828613817691803\n",
            "0.810575544834137\n",
            "0.7872129082679749\n",
            "0.7694396376609802\n",
            "0.7542781233787537\n",
            "0.7386355996131897\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    loss = trainGCN(gcn_computers, dataset_computers.data, gcn_opt_computers, loss_fn)\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8H_4cwxVrHIL"
      },
      "outputs": [],
      "source": [
        "torch.save(gcn_computers.state_dict(), 'gcn_computers_layers.pt')  # saving model's parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "CleVBeAerP8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e2f7dd-2328-47ba-8427-f68610efd68a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13752, 10])\n",
            "0.7910610437393188\n"
          ]
        }
      ],
      "source": [
        "test_acc = testGCN(gcn_computers, dataset_computers.data)\n",
        "print(test_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw3mQDh+lpCYfJK+7u6DzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}