{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedanth-i/483-final-project/blob/main/483_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tex07RZO_rFI"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# geometric_libs = '/content/notebooks'\n",
        "# os.symlink(\"/content/drive/MyDrive/Colab Notebooks\", geometric_libs)\n",
        "# sys.path.insert(0,geometric_libs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lvXY5Ic_pW9",
        "outputId": "fb9e706d-fd24-4219-8866-88a62eed17c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.1.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPiT62Ks_9PH",
        "outputId": "eba9765e-67ff-4ba1-ed14-9e9280e0dd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --target=$geometric_libs torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "#can skip this step next time since already installed on drive\n",
        "#!pip install -r \"/content/drive/MyDrive/Colab Notebooks/requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l21rE2L1_6Eb",
        "outputId": "53baee1b-342b-46c0-90b9-c5d1503728a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --target=$geometric_libs ogb\n",
        "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "# !pip install ogb  # for datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NYvvXigRCCx2"
      },
      "outputs": [],
      "source": [
        "import torch_scatter, torch_sparse, torch_cluster, torch_spline_conv, torch_geometric, ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gtxYGk8KAKvm"
      },
      "outputs": [],
      "source": [
        "# import torch_geometric.data into environment\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric import nn\n",
        "import torch_geometric.transforms as T\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-GiBBMgcAK1M"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Amazon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "UGtlXzAp9LBY"
      },
      "outputs": [],
      "source": [
        "dataset_computers = Amazon('/tmp/amazoncomputers', 'Computers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Fao_enSV9-Gr"
      },
      "outputs": [],
      "source": [
        "dataset_photos = Amazon('/tmp/amazonphotos', 'Photo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dq3KctJ-N1c",
        "outputId": "5e6a767b-208f-45db-e5e7-d2b283ea70f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "dataset_computers.num_classes, dataset_photos.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_GIzPoJINXKm"
      },
      "outputs": [],
      "source": [
        "class MLP1(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(1, -1)\n",
        "        out = 0\n",
        "\n",
        "        out = self.layer_1(x) #linear 1\n",
        "        out = self.act(out) #relu\n",
        "        out = self.layer_2(out) #linear 2\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CHANGE HERE these values to get results\n",
        "\n",
        "hidden_channels = 200 #can change number of hidden channels for variability\n",
        "l_rate = 0.01 #learning rate\n",
        "split = 11000 #train/test split.\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "3jNhKxS0tlRv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "d0hojVFN1iMm"
      },
      "outputs": [],
      "source": [
        "#Computers dataset\n",
        "\n",
        "num_features_computers = dataset_computers.num_features\n",
        "num_classes_computers = dataset_computers.num_classes # please write down the number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ZS00jxIbUYmM"
      },
      "outputs": [],
      "source": [
        "#Photos dataset\n",
        "\n",
        "\n",
        "num_features_photos = dataset_photos.num_features\n",
        "num_classes_photos = dataset_photos.num_classes # please write down the number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "IBPLWfhoTyDD"
      },
      "outputs": [],
      "source": [
        "#define model here\n",
        "\n",
        "#MLP Model\n",
        "\n",
        "model_1_computers = MLP1(num_features_computers, hidden_channels, num_classes_computers)\n",
        "model_1_photos = MLP1(num_features_photos, hidden_channels, num_classes_photos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "nPOFix9C2BRb"
      },
      "outputs": [],
      "source": [
        "optimizer_1_computers = optim.Adam(model_1_computers.parameters(), lr=l_rate)\n",
        "optimizer_1_photos = optim.Adam(model_1_photos.parameters(), lr=l_rate) #play around with the learning rate for differentiating\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "_ra_o24IMVsx"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "    split = len(data.y)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i in range(0, split): #train/test split is 0.8/0.2. For computers, 0.8*13,752 = 11000. For photos 0.8*7650 = 6048\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      y_pred = model(data.x[i])\n",
        "\n",
        "\n",
        "      y_actual = torch.zeros(1,10)\n",
        "      y_actual[0][data.y[i]] = 1\n",
        "\n",
        "      torch.squeeze(y_pred, dim=0)\n",
        "      #print(y_pred.shape, data.y.shape, data.y, y_pred)\n",
        "\n",
        "      l = loss_fn(y_pred, y_actual)  # calculate the loss\n",
        "\n",
        "      l.backward()  # calculate the gradients of each parameter\n",
        "\n",
        "      optimizer.step()  # update the parameters by taking an optimizer step\n",
        "\n",
        "      loss += l.item()\n",
        "\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pblJ0YrdYnZy",
        "outputId": "b1e09c04-f01b-4cbd-da76-f56e4e78351a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Data(x=[13752, 767], edge_index=[2, 491722], y=[13752]), 767, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "dataset_computers.data, dataset_computers.num_features, dataset_computers.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf4DIeLTX-yz",
        "outputId": "a8e40cb9-9922-41a3-c86c-2aa0366f6f49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Data(x=[7650, 745], edge_index=[2, 238162], y=[7650]), 745, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "dataset_photos.data, dataset_photos.num_features, dataset_photos.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "9_kuoSp-wLYa"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(pred, label):\n",
        "\n",
        "  acc = 0.0\n",
        "\n",
        "  new = torch.softmax(pred, dim=1).argmax(dim=1)\n",
        "  # print(new, new.shape)\n",
        "  # print(label.shape)\n",
        "  final = torch.eq(new, label).sum().item()\n",
        "  acc = final/len(pred)\n",
        "\n",
        "\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "BtIBO0D4vet5"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "    epoch_acc = 0\n",
        "    split = 11000\n",
        "\n",
        "    model.eval()\n",
        "    for i in range(split, len(data.y)): #0.2 split for testing. Remainder of examples used. For computers, ~2750 examples. For photos 1512\n",
        "\n",
        "      y_pred = model(data.x[i])\n",
        "\n",
        "      y_actual = torch.zeros(1,10)\n",
        "      y_actual[0][data.y[i]] = 1\n",
        "\n",
        "      #print(y_pred.shape, data.y.shape, data.y, y_pred)\n",
        "\n",
        "      l = loss_fn(y_pred, y_actual)\n",
        "      loss += l.item()\n",
        "      epoch_acc += calculate_accuracy(y_pred, y_actual)\n",
        "\n",
        "\n",
        "    return epoch_acc / len(data.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZzqbOakY4ZL",
        "outputId": "ed8570a5-3d36-4b12-b3aa-29abaacbdcac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21785.21992010533\n",
            "20290.932521068968\n",
            "19739.77181237738\n",
            "19008.79474176968\n",
            "18661.989557041805\n",
            "17030.822358881418\n"
          ]
        }
      ],
      "source": [
        "best_val_acc = final_test_acc = 0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train(model_1_computers, dataset_computers.data, optimizer_1_computers, loss_fn)\n",
        "    print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwxWmzc4Q2wO"
      },
      "outputs": [],
      "source": [
        "#Save model's parameters like such. Can change parameters depending on what model you want to save\n",
        "torch.save(model_1_photos.state_dict(), 'model_photos_200_0.001.pt')  # saving model's parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK1uo-kqRFIy"
      },
      "outputs": [],
      "source": [
        "test_acc = evaluate(model_1_computers, dataset_computers.data, loss_fn)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swSuk_b4kjJa"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN1(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.act = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, node_feature, edge_index):\n",
        "\n",
        "        output = self.conv1(node_feature, edge_index)\n",
        "        output = self.act(output)\n",
        "\n",
        "        #Can add/remove GCN layers\n",
        "\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "        # output = self.conv3(output, edge_index)\n",
        "        # output = self.act(output)\n",
        "\n",
        "\n",
        "        output = self.conv2(output, edge_index)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CHANGE HERE these values to get results\n",
        "\n",
        "hidden_channels = 200 #can change number of hidden channels for variability\n",
        "l_rate = 0.01 #learning rate\n",
        "split = 11000 #train/test split\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "bGRjq3xxuugR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQYvPmdc-CAO"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Computers and Photos\n",
        "\n",
        "num_features_computers = dataset_computers.num_features\n",
        "num_classes_computers = dataset_computers.num_classes # please write down the number of classes\n",
        "\n",
        "num_features_photos = dataset_photos.num_features\n",
        "num_classes_photos = dataset_photos.num_classes # please write down the number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXWvFBWaj6QG"
      },
      "outputs": [],
      "source": [
        "#GCN Models\n",
        "gcn_computers = GCN1(num_features_computers, hidden_channels, num_classes_computers)\n",
        "gcn_photos = GCN1(num_features_photos, hidden_channels, num_classes_photos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpTMuD_ykLab"
      },
      "outputs": [],
      "source": [
        "#GCN Optimizers\n",
        "gcn_opt_computers = optim.Adam(gcn_computers.parameters(), lr=l_rate)\n",
        "gcn_opt_photos = optim.Adam(gcn_photos.parameters(), lr=l_rate) #play around with the learning rate for differentiating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1FXTgXSqea9"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NVC4ytUkvxm"
      },
      "outputs": [],
      "source": [
        "def trainGCN(model, data, optimizer, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(data.x, data.edge_index)\n",
        "\n",
        "    l = loss_fn(y_pred[:split], data.y.view(-1)[:split])  # calculate the loss\n",
        "\n",
        "    l.backward()  # calculate the gradients of each parameter\n",
        "\n",
        "    optimizer.step()  # update the parameters by taking an optimizer step\n",
        "\n",
        "    loss += l.item()\n",
        "\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_zWbF76m-U3"
      },
      "outputs": [],
      "source": [
        "def testGCN(model, data):\n",
        "\n",
        "\n",
        "  acc = 0\n",
        "  model.eval()\n",
        "  pred = model(data.x, data.edge_index)\n",
        "  print(pred.shape)\n",
        "\n",
        "  predicted_classes = torch.argmax(pred[split:], dim=1)\n",
        "  acc = torch.mean((predicted_classes == data.y[split:]).float()).item()\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pHT11cAnYs0"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    loss = trainGCN(gcn_computers, dataset_computers.data, gcn_opt_computers, loss_fn)\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H_4cwxVrHIL"
      },
      "outputs": [],
      "source": [
        "torch.save(gcn_computers.state_dict(), 'gcn_computers_layers.pt')  # saving model's parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CleVBeAerP8S"
      },
      "outputs": [],
      "source": [
        "test_acc = testGCN(gcn_computers, dataset_computers.data)\n",
        "print(test_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCVxbw+h3QGsX7A6SN3y53",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}